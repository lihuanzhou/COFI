# -*- coding: utf-8 -*-
"""06.WRI COFI_Cleaning_REFINITIV_LOAN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v4eLrdTchUMyYE-uAF0hJLmPxGpQ7Pr-

Load Libraries
"""

import pandas as pd
import numpy as np
import re
import datetime
# IMPORT LOCAL FUNCTIONS
from COFI_cleaning_functions import extract_plant, extract_capacity, extract_fuel, extract_fuel_proxy, region_clean

"""### Set Variables
These variables can be adjusted upfront or via frontend platform without visiting the algorithm code
"""

# Set source data location
#path = r'G:\My Drive\ZFG Insights\Project Folder\51. WRI\1. COFI NLP Project\4. Cleaned Data Source'

# Load Master Mapping file
mapping = './Mapping Files/COFI Mapping_columns.xlsx'
mapping_source_sheet = 'Source'

# Load the name of source dataset for this code
source_name = 'REFINITIV_LOAN' 

# Load fuel mapping file
fuel_map = './Mapping Files/STI-reference_primary-fuel-mapping.xlsx'

# Cleand file output directory
outname = './Cleaned Data/'

"""### Load source data"""

# Set master path
# import os
# os.chdir(path)

# Load Master mapping file
map_df = pd.read_excel(mapping, sheet_name = mapping_source_sheet)

map_temp = map_df.loc[map_df['Source_Name'] == source_name]
map_temp = map_temp.reset_index(drop = True)

# Load fuel mapping file
fuel_map = pd.read_excel(fuel_map)

map_temp

# Load source data
# handle in case there are multiple files per source database

# This only applies to Refinitiv Loan

if len(map_temp) > 1:
    appended_data = []
    print("FILES SEEN BY CLEANING LOAN SCRIPT")
    for i in map_temp.index:
        # load Source Data
        filename = map_temp.loc[i,'File_Name']
        print(filename)
        starting_row = map_temp.loc[i,'Starting_row']
        sheet = map_temp.loc[i,'Sheet_name']

        # This only applies to Refinitiv Loan
        if "Project Finance_2021-2023" in filename:
            df = pd.read_excel(filename, skiprows=starting_row)
            df.columns = [col.replace('\n(Σ=Com)', '').replace('\n(True)', '').replace('(Full Name)','(Name)').replace('Loans Loan Dates: Financial Close Date of Facility','Loan Dates: Facility Closing Date').replace('Loans Loan Dates: Facility Closing Date','Loan Dates: Facility Closing Date').replace('Loans TRBC','TRBC') for col in df.columns]
            # Drop rows where either 'Deal PermID' or 'Loan Deal Identifier' is NaN
            df = df.dropna(subset=['Deal PermID', 'Loan Deal Identifier'], how='any')
            # Drop rows if () in column (these are overview rows, not actual rows
            df = df[~df['Loan Deal Identifier'].str.contains(r'\(', na=False)]
        elif '.xls' in filename:
            if pd.notna(sheet):
                df = pd.read_excel(filename, sheet_name=sheet, skiprows=starting_row)
                # customized to Refinitiv Loan
                df.columns = [col.replace('\n(Σ=Com)', '').replace('\n(True)', '').replace('(Full Name)','(Name)').replace("\n('|')", '').replace(", '|'", '').replace('Loans Loan Dates: Financial Close Date of Facility','Loan Dates: Facility Closing Date').replace('Loans Loan Dates: Facility Closing Date','Loan Dates: Facility Closing Date').replace('Loans TRBC','TRBC') for col in df.columns]
            else:
                df = pd.read_excel(filename, skiprows=starting_row)
                # customized to Refinitiv Loan
                df.columns = [col.replace('\n(Σ=Com)', '').replace('\n(True)', '').replace('(Full Name)','(Name)').replace("\n('|')", '').replace(", '|'", '').replace('Loans Loan Dates: Financial Close Date of Facility','Loan Dates: Facility Closing Date').replace('Loans Loan Dates: Facility Closing Date','Loan Dates: Facility Closing Date').replace('Loans TRBC','TRBC') for col in df.columns]
        elif filename.endswith('.csv'):
            df = pd.read_csv(filename)

        appended_data.append(df)

    df = pd.concat(appended_data)
    df = df.reset_index(drop = True)

else:
    # load Source Data
    filename = map_temp.loc[0,'File_Name']
    print(filename)
    starting_row = map_temp.loc[0,'Starting_row']
    sheet = map_temp.loc[0,'Sheet_name']

    if '.xls' in filename:
        if pd.notna(sheet):
            df = pd.read_excel(filename, sheet_name=sheet, skiprows=starting_row)
        else:
            df = pd.read_excel(filename, skiprows=starting_row)
    elif filename.endswith('.csv'):
        df = pd.read_csv(filename)

print("SCRIPT IS CONTINUING!!")
print(df.columns)

"""### Clean Source Data
This chunk of code is customized per source database.

Variables need cleaning are listed in the Mapping file

#### Filter

1. input missing values per row, group by values in "All Managers, inc. Int'l Co-Managers (Name)". Ignore Paricipants column
"""
print("1. input missing values per row, group by values in 'Deal PermID'")
# directly using groupby.ffill() will make "Deal permID" column disappear
df_filled = df.groupby('Deal PermID', as_index=False).apply(lambda x: x.fillna(method="ffill"))

df_filled.reset_index(inplace=True)

df = df_filled.drop(columns = ['level_0','level_1'])

print(df.shape)

"""2. filter by Chinese banks in column "All Managers, inc. Int'l Co-Managers (Full Name)"
"""
print("2. filter by Chinese banks in column 'All Managers, inc. Int'l Co-Managers (Full Name)'")
keywords = 'china|haitong|communication|silk|sino|shanghai|beijing|zhejiang|shenzhen|guangdong|guangzhou|hua xia|ping an|\bicbc\b|\bccb\b|\bicbc\b|\bboc\b|\bcmb\b|\bspdb\b|\bcmbc\b|\bbocom\b|\bpsbc\b|\bcncb\b|\bpab\b|\bceb\b|\bibc\b|\bgdb\b|\bcgb\b|\bcdb\b|\bexim\b|\bccbc\b|\bcncbi\b|\bczb\b|\bchexim\b|\bcmdca\b|\bcmec\b'
remove = 'hongkong|hsbc|\bkbc\b|arab|varesino'

df = df[df["All Managers, inc. Int'l Co-Managers (Name)"].str.contains(keywords, case=False, na=False)]
df = df[~df["All Managers, inc. Int'l Co-Managers (Name)"].str.contains(remove, case=False, na=False)]

print(df.shape)

"""3. remove destination in China mainland, Taiwan and Hongkong in column "Issuer/Borrower Nation"
"""
print("3. remove destination in China mainland, Taiwan and Hongkong in column 'Issuer/Borrower Nation'")
df = df[df["Issuer/Borrower Nation"] != "China (Mainland)"]
df = df[df["Issuer/Borrower Nation"] != "Taiwan"]
df = df[df["Issuer/Borrower Nation"] != "Hong Kong"]

print(df.shape)

"""4. Remove rows with "general corporate purpose" in use of proceed note, and without any plant mentioned"""
print("4. Remove rows with 'general corporate purpose' in use of proceed note, and without any plant mentioned")
# Regex pattern to detect the presence of specific keywords, without "refinancing facility"
keywords_pattern = r'\b(plant(s)?|station(s)?|project(s)?|(power|generation|generating) facility(s)?|farm(s)?|generation(s)?|field(s)?|generator(s)?|dam(s)?|LNG|pole(s)?|hydropower|drill(ing)?|park(s)?|onshore)\b'

df['Use of Proceeds Notes'] = df['Use of Proceeds Notes'].fillna('')

# Filter condition 1: Check for "General Corporate Purpose"
condition1 = df['Use of Proceeds Notes'].str.contains('general corporate purpose', flags=re.IGNORECASE)

# Filter condition 2: Ensure none of the keywords are present
condition2 = ~df['Use of Proceeds Notes'].str.contains(keywords_pattern, flags=re.IGNORECASE | re.MULTILINE)

# Combine conditions
df =  df[~(condition1 & condition2)]

print(df.shape)

"""#### Map columns and Convert Units
1. create new, modified columns based on mapping to final variables, as indicated in the mapping file
2. convert units of currency, unit, and capacity unit during step 1
"""

# Transform variables for future matching
df = df.reset_index(drop = True)
for i in df.index:

    # Create a new column mapping to "power_plant_name"
    df.loc[i,'power_plant_name'] = extract_plant(df.loc[i, 'Issuer/Borrower Name Full'])
    # If no power plant name from Issuer/Borrower Name Full', then try 'Use of Proceeds Notes' column
    if df.loc[i,'power_plant_name'] == '' or df.loc[i, 'power_plant_name'] is None:
        df.loc[i,'power_plant_name'] = extract_plant(df.loc[i,'Use of Proceeds Notes'])

    # Create a new column mapping to "primary_fuel" from Use of Proceeds Notes column
    df.loc[i,'primary_fuel'] = extract_fuel_proxy(df.loc[i,'Use of Proceeds Notes'])

    # Create a new column mapping to "installed_capacity" from Use of Proceeds Notes column
    if df.loc[i, 'power_plant_name'] is not None and any(x in df.loc[i, 'power_plant_name'] for x in ['MW', 'GW', 'KW']):
        df.loc[i,'installed_capacity'] = extract_capacity(df.loc[i,'power_plant_name'])
    else:
        df.loc[i,'installed_capacity'] = extract_capacity(df.loc[i,'Use of Proceeds Notes'])

# Rename variables into final database names if the variable doesn't need transformation

# load variable names, which are the variables labeled in mapping file but without a Note.
df_var = pd.read_excel(mapping, sheet_name = source_name)
df_var = df_var[df_var['Note'].isna() & df_var[source_name].notna()]
df_var = df_var.reset_index(drop = True)
variables = df_var[source_name].tolist()

# rename each variable
for j in df_var.index:
    old_name = df_var.loc[j,source_name]
    new_name = df_var.loc[j,'Column_name']
    df[new_name] = df[old_name]

print("SCRIPT IS CONTINUING _ V2!!")


"""### Save cleaned data"""

df.to_excel(outname + source_name + '.xlsx', index = False)

df

